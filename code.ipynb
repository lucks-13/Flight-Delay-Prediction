{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Flight Delay Prediction\n",
        "This notebook predicts a flight delay using usa airport traffic dataset."
      ],
      "metadata": {
        "id": "mR87_4sc0kPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Setup"
      ],
      "metadata": {
        "id": "oiHzc9ap1F0v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPmxAP2L0eci"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import jarque_bera, normaltest, shapiro\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, QuantileTransformer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor\n",
        "from sklearn.ensemble import StackingRegressor, BaggingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Initial Exploration"
      ],
      "metadata": {
        "id": "c1zt263C1KFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_or_create_dataset():\n",
        "    url = \"https://raw.githubusercontent.com/plotly/datasets/master/2011_february_us_airport_traffic.csv\"\n",
        "    try:\n",
        "        df = pd.read_csv(url)\n",
        "        print(f\"Successfully loaded dataset from URL. Shape: {df.shape}\")\n",
        "        print(f\"Columns: {df.columns.tolist()}\")\n",
        "\n",
        "        if 'delay_minutes' not in df.columns:\n",
        "            print(\"Dataset doesn't have delay_minutes column. Creating synthetic dataset...\")\n",
        "            return create_synthetic_dataset()\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load dataset from URL: {e}\")\n",
        "        print(\"Creating synthetic dataset...\")\n",
        "        return create_synthetic_dataset()\n",
        "\n",
        "def create_synthetic_dataset():\n",
        "    np.random.seed(42)\n",
        "    n_samples = 20000\n",
        "\n",
        "    airlines = ['AA', 'UA', 'DL', 'WN', 'B6', 'AS', 'NK', 'F9', 'G4', 'SY']\n",
        "    airports = ['JFK', 'LAX', 'ORD', 'DFW', 'DEN', 'SFO', 'SEA', 'LAS', 'PHX', 'IAH',\n",
        "                'ATL', 'BOS', 'CLT', 'DTW', 'MSP', 'PHL', 'MIA', 'LGA', 'BWI', 'MDW']\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'airline': np.random.choice(airlines, n_samples),\n",
        "        'origin': np.random.choice(airports, n_samples),\n",
        "        'destination': np.random.choice(airports, n_samples),\n",
        "        'scheduled_departure': np.random.randint(500, 2300, n_samples),\n",
        "        'distance': np.random.gamma(2, 500, n_samples),\n",
        "        'day_of_week': np.random.randint(1, 8, n_samples),\n",
        "        'month': np.random.randint(1, 13, n_samples),\n",
        "        'weather_delay': np.random.exponential(5, n_samples),\n",
        "        'security_delay': np.random.exponential(2, n_samples),\n",
        "        'aircraft_delay': np.random.exponential(3, n_samples),\n",
        "        'late_aircraft_delay': np.random.exponential(4, n_samples),\n",
        "        'air_traffic_delay': np.random.exponential(3, n_samples),\n",
        "    })\n",
        "\n",
        "    df = df[df['origin'] != df['destination']]\n",
        "\n",
        "    base_delay = (\n",
        "        df['distance'] / 100 +\n",
        "        df['weather_delay'] +\n",
        "        df['security_delay'] +\n",
        "        df['aircraft_delay'] +\n",
        "        df['late_aircraft_delay'] +\n",
        "        df['air_traffic_delay'] +\n",
        "        np.where(df['day_of_week'].isin([1, 7]), 15, 0) +\n",
        "        np.where(df['month'].isin([6, 7, 12]), 10, 0) +\n",
        "        np.where(df['scheduled_departure'] < 700, 5, 0) +\n",
        "        np.where(df['scheduled_departure'] > 2000, 12, 0) +\n",
        "        np.random.normal(0, 8, len(df))\n",
        "    )\n",
        "\n",
        "    df['delay_minutes'] = np.maximum(0, base_delay)\n",
        "\n",
        "    df['is_weekend'] = df['day_of_week'].isin([6, 7]).astype(int)\n",
        "    df['is_holiday_season'] = df['month'].isin([6, 7, 11, 12]).astype(int)\n",
        "    df['departure_hour'] = df['scheduled_departure'] // 100\n",
        "    df['is_peak_hour'] = df['departure_hour'].isin([7, 8, 17, 18, 19]).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_or_create_dataset()\n",
        "\n",
        "print(f\"Final dataset shape: {df.shape}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "4hSlBKJP1KsY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}